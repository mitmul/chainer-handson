
# Chainer: ãƒ“ã‚®ãƒŠãƒ¼å‘ã‘ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ« Vol.2

ã“ã“ã§ã¯ã€Animeface-Characterãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦ã€146ç¨®é¡ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é¡”ç”»åƒã‚’90%ä»¥ä¸Šã®ç²¾åº¦ã§åˆ†é¡ã™ã‚‹ã¨ã„ã†èª²é¡Œã‚’é€šã—ã¦ã€ä»¥ä¸‹ã®ã“ã¨ã‚’èª¬æ˜ã—ã¾ã™ã€‚

- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œã‚‹æ–¹æ³•
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¨“ç·´ç”¨ãƒ»æ¤œè¨¼ç”¨ã«åˆ†å‰²ã™ã‚‹æ–¹æ³•
- è¨“ç·´æ¸ˆã¿é‡ã¿ã‚’æŒã£ã¦ãã¦æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã§Fine-tuningã™ã‚‹æ–¹æ³•
- ï¼ˆãŠã¾ã‘ï¼šãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹ã‚’ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒã§æ›¸ãæ–¹æ³•ï¼‰

ä½¿ç”¨ã—ãŸç’°å¢ƒã¯ä»¥ä¸‹ã§ã™ã€‚

- NVIDIA Pascal TITAN X
- Ubuntu 16.04

ä½¿ç”¨ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ä»¥ä¸‹ã§ã™ã€‚

- Chainer 2.0.1
- CuPy 1.0.1
- Pillow
- tqdm

ã“ã“ã§ã¯ã€**Chainerã«äºˆã‚ç”¨æ„ã•ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¤–éƒ¨ã‹ã‚‰èª¿é”ã—ã¦**ã€Chainerã§è¨˜è¿°ã•ã‚ŒãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è¨“ç·´ã®ãŸã‚ã«ç”¨ã„ã‚‹æ–¹æ³•ã‚’å…·ä½“ä¾‹ã‚’ã‚‚ã£ã¦ç¤ºã—ã¾ã™ã€‚åŸºæœ¬çš„ãªæ‰‹é †ã¯ã»ã¼[Chainer: ãƒ“ã‚®ãƒŠãƒ¼å‘ã‘ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ« Vol.1](http://qiita.com/mitmul/items/eccf4e0a84cb784ba84a)ã§èª¬æ˜ã—ãŸCIFAR10ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹ã‚’æ‹¡å¼µã™ã‚‹ç« ã¨å¤‰ã‚ã‚Šã¾ã›ã‚“ã€‚

ä»Šå›ã¯ã¤ã„ã§ã«ChainerãŒç”¨æ„ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹ç”¨ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ä¸€ã¤ã§ã‚ã‚‹`split_dataset_random`ã‚’ä½¿ã„ã€**å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®åˆ†å‰²ã‚’ç°¡å˜ã«è¡Œã†æ–¹æ³•**ã‚‚åˆã‚ã›ã¦èª¬æ˜ã—ã¦ã¿ã¾ã™ã€‚

ã¾ãŸã€**ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã¨ä¼¼ãŸãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦äºˆã‚è¨“ç·´ã•ã‚ŒãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é‡ã¿ã‚’åˆæœŸå€¤ã¨ã—ã¦ç”¨ã„ã‚‹æ–¹æ³•**ã‚‚èª¬æ˜ã—ã¾ã™ã€‚Caffeã®.caffemodelã®å½¢ã§é…å¸ƒã•ã‚Œã¦ã„ã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’Fine-tuningã—ãŸã„å ´åˆã€ã“ã®è¨˜äº‹ã¨ã»ã¼åŒæ§˜ã®æ‰‹é †ãŒé©ç”¨ã§ãã‚‹ã¨æ€ã„ã¾ã™ã€‚

ã“ã®è¨˜äº‹ã¯[ã‚‚ã¨ã‚‚ã¨Jupyter notebookã§æ›¸ã„ãŸã‚‚ã®](https://github.com/mitmul/chainer-handson/blob/master/5-Write-new-dataset-class_ja.ipynb)ã‚’ `jupyter nbconvert --to markdown 5-Write-new-dataset-class_ja.ipynb` ã—ãŸã‚‚ã®ã§ã™ã€‚

## 1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

ã¾ãšã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã¾ã™ã€‚ä»Šå›ã¯ã€Kaggle Grand Masterã§ã‚ã‚‰ã›ã‚‰ã‚Œã‚‹nagadomiã•ã‚“ãŒ[ã“ã¡ã‚‰](http://www.nurs.or.jp/~nagadomi/animeface-character-dataset/)ã§é…å¸ƒã•ã‚Œã¦ã„ã‚‹ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®é¡”é ˜åŸŸã‚µãƒ ãƒã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚


```python
%%bash
if [ ! -d animeface-character-dataset ]; then
    curl -L -O http://www.nurs.or.jp/~nagadomi/animeface-character-dataset/data/animeface-character-dataset.zip
    unzip animeface-character-dataset.zip
    rm -rf animeface-character-dataset.zip
fi
```

ä½¿ç”¨ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’pipã§å…¥ã‚Œã¾ã™ã€‚


```python
%%bash
pip install chainer
pip install cupy
pip install Pillow
pip install tqdm
```

    Requirement already satisfied: chainer in /home/shunta/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages
    Requirement already satisfied: filelock in /home/shunta/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/filelock-2.0.8-py3.6.egg (from chainer)
    Requirement already satisfied: nose in /home/shunta/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages (from chainer)
    Requirement already satisfied: six>=1.9.0 in /home/shunta/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages (from chainer)
    Requirement already satisfied: protobuf>=2.6.0 in /home/shunta/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/protobuf-3.3.0-py3.6.egg (from chainer)
    Requirement already satisfied: numpy>=1.9.0 in /home/shunta/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages (from chainer)
    Requirement already satisfied: setuptools in /home/shunta/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/setuptools-27.2.0-py3.6.egg (from protobuf>=2.6.0->chainer)
    Requirement already satisfied: cupy in /home/shunta/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages
    Requirement already satisfied: nose in /home/shunta/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages (from cupy)
    Requirement already satisfied: numpy>=1.9.0 in /home/shunta/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages (from cupy)
    Requirement already satisfied: six>=1.9.0 in /home/shunta/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages (from cupy)
    Requirement already satisfied: Pillow in /home/shunta/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages
    Requirement already satisfied: olefile in /home/shunta/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages (from Pillow)
    Requirement already satisfied: tqdm in /home/shunta/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages


## 2. å•é¡Œè¨­å®šã®ç¢ºèª

ä»Šå›ã¯ã€animeface-character-datasetã«å«ã¾ã‚Œã‚‹æ§˜ã€…ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®é¡”ç”»åƒã‚’ç”¨ã„ã¦ã€æœªçŸ¥ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é¡”ç”»åƒãŒå…¥åŠ›ã•ã‚ŒãŸéš›ã«ã€ãã‚ŒãŒæ—¢çŸ¥ã®ã‚¯ãƒ©ã‚¹ä¸€è¦§ã®ä¸­ã®ã©ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®é¡”ã‚‰ã—ã„ã‹ã‚’å‡ºåŠ›ã™ã‚‹ã‚ˆã†ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è¨“ç·´ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚

ãã®éš›ã«ã€**ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–ã—ãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è¨“ç·´ã™ã‚‹ã®ã§ã¯ãªãã€äºˆã‚ä¼¼ãŸãƒ‰ãƒ¡ã‚¤ãƒ³ã§è¨“ç·´æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç›®çš„ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§Fine-tuningã™ã‚‹**ã¨ã„ã†ã‚„ã‚Šæ–¹ã‚’ã—ã¦ã¿ã¾ã™ã€‚

ä»Šå›å­¦ç¿’ã«ç”¨ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªç”»åƒã‚’å¤šæ•°å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã”ã¨ã«äºˆã‚ãƒ•ã‚©ãƒ«ãƒ€åˆ†ã‘ãŒã•ã‚Œã¦ã„ã¾ã™ã€‚ãªã®ã§ã€ä»Šå›ã‚‚ã‚ªãƒ¼ã‚½ãƒ‰ãƒƒã‚¯ã‚¹ãªç”»åƒåˆ†é¡å•é¡Œã¨ãªã‚Šã¾ã™ã€‚

#### é©å½“ã«æŠœãå‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«

| 000_hatsune_miku | 002_suzumiya_haruhi | 007_nagato_yuki | 012_asahina_mikuru |
|:-:|:-:|:-:|:-:|
| ![](animeface-character-dataset/thumb/000_hatsune_miku/face_128_326_108.png) | ![](animeface-character-dataset/thumb/002_suzumiya_haruhi/face_1000_266_119.png) | ![](animeface-character-dataset/thumb/007_nagato_yuki/face_83_270_92.png) | ![](animeface-character-dataset/thumb/012_asahina_mikuru/face_121_433_128.png) |

## 3. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ

ã“ã“ã§ã¯ã€ç”»åƒåˆ†é¡ã®å•é¡Œã§ã‚ˆãä½¿ã‚ã‚Œã‚‹`LabeledImageDataset`ã¨ã„ã†ã‚¯ãƒ©ã‚¹ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆæ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚ã¾ãšã¯ã€Pythonæ¨™æº–ã®æ©Ÿèƒ½ã‚’ä½¿ã£ã¦ä¸‹æº–å‚™ã‚’ã—ã¾ã™ã€‚

åˆã‚ã«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ‘ã‚¹ä¸€è¦§ã‚’å–å¾—ã—ã¾ã™ã€‚ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€`animeface-character-dataset/thumb`ä»¥ä¸‹ã«ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã”ã¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«åˆ†ã‘ã‚‰ã‚Œã¦å…¥ã£ã¦ã„ã¾ã™ã€‚ä¸‹è¨˜ã®ã‚³ãƒ¼ãƒ‰ã§ã¯ã€ãƒ•ã‚©ãƒ«ãƒ€å†…ã«`ignore`ã¨ã„ã†ãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¥ã£ã¦ã„ã‚‹å ´åˆã¯ã€ãã®ãƒ•ã‚©ãƒ«ãƒ€ã®ç”»åƒã¯ç„¡è¦–ã™ã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚


```python
import os
import glob
from itertools import chain

# ç”»åƒãƒ•ã‚©ãƒ«ãƒ€
IMG_DIR = 'animeface-character-dataset/thumb'

# å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã”ã¨ã®ãƒ•ã‚©ãƒ«ãƒ€
dnames = glob.glob('{}/*'.format(IMG_DIR))

# ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ä¸€è¦§
fnames = [glob.glob('{}/*.png'.format(d)) for d in dnames
          if not os.path.exists('{}/ignore'.format(d))]
fnames = list(chain.from_iterable(fnames))
```

æ¬¡ã«ã€ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ã†ã¡ç”»åƒãŒå«ã¾ã‚Œã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã®éƒ¨åˆ†ãŒã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã‚’è¡¨ã—ã¦ã„ã‚‹ã®ã§ã€ãã‚Œã‚’ä½¿ã£ã¦å„ç”»åƒã«ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã”ã¨ã«ä¸€æ„ã«ãªã‚‹ã‚ˆã†ãªIDã‚’ä½œã‚Šã¾ã™ã€‚


```python
# ãã‚Œãã‚Œã«ãƒ•ã‚©ãƒ«ãƒ€åã‹ã‚‰ä¸€æ„ãªIDã‚’ä»˜ä¸
labels = [os.path.basename(os.path.dirname(fn)) for fn in fnames]
dnames = [os.path.basename(d) for d in dnames
          if not os.path.exists('{}/ignore'.format(d))]
labels = [dnames.index(l) for l in labels]
```

ã§ã¯ã€ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œã‚Šã¾ã™ã€‚ã‚„ã‚Šæ–¹ã¯ç°¡å˜ã§ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨ãã®ãƒ©ãƒ™ãƒ«ãŒä¸¦ã‚“ã ã‚¿ãƒ—ãƒ«ã®ãƒªã‚¹ãƒˆã‚’`LabeledImageDataset`ã«æ¸¡ã›ã°è‰¯ã„ã ã‘ã§ã™ã€‚ã“ã‚Œã¯ `(img, label)` ã®ã‚ˆã†ãªã‚¿ãƒ—ãƒ«ã‚’è¿”ã™ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã«ãªã£ã¦ã„ã¾ã™ã€‚


```python
from chainer.datasets import LabeledImageDataset

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
d = LabeledImageDataset(list(zip(fnames, labels)))
```

æ¬¡ã«ã€ChainerãŒæä¾›ã—ã¦ã„ã‚‹`TransformDataset`ã¨ã„ã†ä¾¿åˆ©ãªæ©Ÿèƒ½ã‚’ä½¿ã£ã¦ã¿ã¾ã™ã€‚ã“ã‚Œã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨å„ãƒ‡ãƒ¼ã‚¿ã¸ã®å¤‰æ›ã‚’è¡¨ã™é–¢æ•°ã‚’å–ã‚‹ãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹ã§ã€ã“ã‚Œã‚’ä½¿ã†ã¨data augmentationã‚„å‰å‡¦ç†ãªã©ã‚’è¡Œã†éƒ¨åˆ†ã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹ã®å¤–ã«ç”¨æ„ã—ã¦ãŠãã“ã¨ãŒã§ãã¾ã™ã€‚


```python
from chainer.datasets import TransformDataset
from PIL import Image

width, height = 160, 160

# ç”»åƒã®resizeé–¢æ•°
def resize(img):
    img = Image.fromarray(img.transpose(1, 2, 0))
    img = img.resize((width, height), Image.BICUBIC)
    return np.asarray(img).transpose(2, 0, 1)

# å„ãƒ‡ãƒ¼ã‚¿ã«è¡Œã†å¤‰æ›
def transform(inputs):
    img, label = inputs
    img = img[:3, ...]
    img = resize(img.astype(np.uint8))
    img = img - mean[:, None, None]
    img = img.astype(np.float32)
    # ãƒ©ãƒ³ãƒ€ãƒ ã«å·¦å³åè»¢
    if np.random.rand() > 0.5:
        img = img[..., ::-1]
    return img, label

# å¤‰æ›ä»˜ããƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã™ã‚‹
td = TransformDataset(d, transform)
```

ã“ã†ã™ã‚‹ã“ã¨ã§ã€`LabeledImageDataset`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã‚ã‚‹`d`ãŒè¿”ã™ `(img, label)` ã®ã‚ˆã†ãªã‚¿ãƒ—ãƒ«ã‚’å—ã‘å–ã£ã¦ã€ãã‚Œã‚’`transform`é–¢æ•°ã«ããã‚‰ã›ã¦ã‹ã‚‰è¿”ã™ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒä½œã‚Œã¾ã—ãŸã€‚

ã§ã¯ã€ã“ã‚Œã‚’å­¦ç¿’ç”¨ã¨æ¤œè¨¼ç”¨ã®2ã¤ã®éƒ¨åˆ†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«splitã—ã¾ã—ã‚‡ã†ã€‚ä»Šå›ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã®ã†ã¡80%ã‚’å­¦ç¿’ç”¨ã«ã€æ®‹ã‚Š20%ã‚’æ¤œè¨¼ç”¨ã«ä½¿ã†ã“ã¨ã«ã—ã¾ã™ã€‚`split_dataset_random`ã‚’ä½¿ã†ã¨ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ãŸã®ã¡ã«ã€æŒ‡å®šã—ãŸåŒºåˆ‡ã‚Šç›®ã§åˆ†å‰²ã—ãŸã‚‚ã®ã‚’è¿”ã—ã¦ãã‚Œã¾ã™ã€‚


```python
from chainer import datasets

train, valid = datasets.split_dataset_random(td, int(len(d) * 0.8), seed=0)
```

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†å‰²ã¯ä»–ã«ã‚‚ã€äº¤å·®æ¤œå®šã‚’ã™ã‚‹ãŸã‚ã®è¤‡æ•°ã®äº’ã„ã«ç•°ãªã‚‹è¨“ç·´ãƒ»æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒšã‚¢ã‚’è¿”ã™ã‚ˆã†ãª`get_cross_validation_datasets_random`ãªã©ã€ã„ãã¤ã‹ã®é–¢æ•°ãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã¡ã‚‰ã‚’ã”è¦§ãã ã•ã„ã€‚ï¼š[SubDataset](https://docs.chainer.org/en/stable/reference/datasets.html#subdataset)

ã•ã¦ã€å¤‰æ›ã®ä¸­ã§ä½¿ã£ã¦ã„ã‚‹`mean`ã¯ã€ä»Šå›ä½¿ã†å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã‚‹ç”»åƒã®å¹³å‡ç”»åƒã§ã™ã€‚ã“ã‚Œã‚’è¨ˆç®—ã—ã¦ãŠãã¾ã—ã‚‡ã†ã€‚


```python
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm_notebook

# å¹³å‡ç”»åƒãŒæœªè¨ˆç®—ãªã‚‰è¨ˆç®—ã™ã‚‹
if not os.path.exists('image_mean.npy'):
    # å¤‰æ›ã‚’ã‹ã¾ã•ãªã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å¹³å‡ã‚’è¨ˆç®—ã—ãŸã„
    t, _ = datasets.split_dataset_random(d, int(len(d) * 0.8), seed=0)

    mean = np.zeros((3, height, width))
    for img, _ in tqdm_notebook(t, desc='Calc mean'):
        img = resize(img[:3].astype(np.uint8))
        mean += img
    mean = mean / float(len(d))
    np.save('image_mean', mean)
else:
    mean = np.load('image_mean.npy')
```

è©¦ã—ã«è¨ˆç®—ã—ãŸå¹³å‡ç”»åƒã‚’è¡¨ç¤ºã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚


```python
# å¹³å‡ç”»åƒã®è¡¨ç¤º
plt.imshow(mean.transpose(1, 2, 0) / 255)
plt.show()
```


![png](5-Write-new-dataset-class_ja_files/5-Write-new-dataset-class_ja_20_0.png)


ãªã‚“ã‹æ€–ã„ã§ã™ã­â€¦

å¹³å‡ã‚’å¼•ãã¨ãã¯ãƒ”ã‚¯ã‚»ãƒ«ã”ã¨ã®å¹³å‡ã«ã—ã¦ã—ã¾ã†ã®ã§ã€ã“ã®å¹³å‡ç”»åƒã®å¹³å‡ãƒ”ã‚¯ã‚»ãƒ«ã‚’è¨ˆç®—ã—ã¦ãŠãã¾ã™ã€‚


```python
mean = mean.mean(axis=(1, 2))
```

## 4. ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ã¨Fine-tuningã®æº–å‚™

ã§ã¯æ¬¡ã«ã€è¨“ç·´ã‚’è¡Œã†ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ã‚’è¡Œã„ã¾ã™ã€‚ã“ã“ã§ã¯[Illustration2Vec](http://illustration2vec.net/)ã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ã€ãã®æœ€å¾Œã®2å±¤ã‚’å‰Šé™¤ã—ã¦ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã•ã‚ŒãŸ3ã¤ã®å…¨çµåˆå±¤ã‚’ä»˜ã‘åŠ ãˆãŸã‚‚ã®ã‚’æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¾ã™ã€‚

å­¦ç¿’æ™‚ã«ã¯ã€Illustration2Vecç”±æ¥ã®éƒ¨åˆ†ï¼ˆ3å±¤ç›®ä»¥ä¸‹ã®éƒ¨åˆ†ï¼‰ã®é‡ã¿ã¯å›ºå®šã—ã¦ãŠãã¾ã™ã€‚ã¤ã¾ã‚Šã€æ–°ãŸã«è¿½åŠ ã—ãŸ3ã¤ã®å…¨çµåˆå±¤ã ã‘ã‚’è¨“ç·´ã—ã¾ã™ã€‚

ã¾ãšã€é…å¸ƒã•ã‚Œã¦ã„ã‚‹Illustration2Vecãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã¾ã™ã€‚


```python
%%bash
if [ ! -f illust2vec_ver200.caffemodel ]; then
    curl -L -O http://illustration2vec.net/models/illust2vec_ver200.caffemodel
fi
```

ã“ã®è¨“ç·´æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯caffemodelã®å½¢å¼ã§æä¾›ã•ã‚Œã¦ã„ã¾ã™ãŒã€Chainerã«ã¯éå¸¸ã«ç°¡å˜ã«Caffeã®è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€æ©Ÿèƒ½ï¼ˆ`CaffeFunction`ï¼‰ãŒã‚ã‚‹ã®ã§ã€ã“ã‚Œã‚’ä½¿ã£ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚ãŸã ã—ã€èª­ã¿è¾¼ã¿ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€ä¸€åº¦èª­ã¿è¾¼ã‚“ã éš›ã«å¾—ã‚‰ã‚Œã‚‹`Chain`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’Pythonæ¨™æº–ã®`pickle`ã‚’ä½¿ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦ãŠãã¾ã™ã€‚ã“ã†ã™ã‚‹ã“ã¨ã§æ¬¡å›ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ãŒé€Ÿããªã‚Šã¾ã™ã€‚

å®Ÿéš›ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚³ãƒ¼ãƒ‰ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚


```python
import pickle

import chainer
import chainer.links as L
import chainer.functions as F

from chainer import Chain
from chainer.links.caffe import CaffeFunction


class Illust2Vec(Chain):

    CAFFEMODEL_FN = 'illust2vec_ver200.caffemodel'
    PKL_FN = 'illust2vec_ver200.pkl'

    def __init__(self, n_classes, unchain=True):
        w = chainer.initializers.HeNormal()        
        if not os.path.exists(self.PKL_FN):  # å¤‰æ›æ¸ˆã¿ã®Chainerãƒ¢ãƒ‡ãƒ«ï¼ˆPKLãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ãŒç„¡ã„å ´åˆ
            model = CaffeFunction(self.CAFFEMODEL_FN)  # CaffeModelã‚’èª­ã¿è¾¼ã‚“ã§ä¿å­˜ã—ã¾ã™ã€‚ï¼ˆæ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰
            pickle.dump(model, open(self.PKL_FN, 'wb'))  # ä¸€åº¦èª­ã¿è¾¼ã‚“ã ã‚‰ã€æ¬¡å›ã‹ã‚‰é«˜é€Ÿã«èª­ã¿è¾¼ã‚ã‚‹ã‚ˆã†Pickleã—ã¾ã™ã€‚
        else:
            model = pickle.load(open(self.PKL_FN, 'rb'))
        del model.encode1  # ãƒ¡ãƒ¢ãƒªç¯€ç´„ã®ãŸã‚ä¸è¦ãªãƒ¬ã‚¤ãƒ¤ã‚’å‰Šé™¤ã—ã¾ã™ã€‚
        del model.encode2
        del model.forwards['encode1']
        del model.forwards['encode2']
        model.layers = model.layers[:-2]
        
        super(Illust2Vec, self).__init__()
        with self.init_scope():
            self.trunk = model  # å…ƒã®Illust2Vecãƒ¢ãƒ‡ãƒ«ã‚’trunkã¨ã—ã¦ã“ã®ãƒ¢ãƒ‡ãƒ«ã«å«ã‚ã¾ã™ã€‚
            self.fc7 = L.Linear(None, 4096, initialW=w)
            self.bn7 = L.BatchNormalization(4096)
            self.fc8 = L.Linear(4096, n_classes, initialW=w)
            
        self.unchain = True

    def __call__(self, x):
        h = self.trunk({'data': x}, ['conv6_3'])[0]  # å…ƒã®Illust2Vecãƒ¢ãƒ‡ãƒ«ã®conv6_3ã®å‡ºåŠ›ã‚’å–ã‚Šå‡ºã—ã¾ã™ã€‚
        if self.unchain:
            h.unchain_backward()
        h = F.dropout(F.relu(self.bn7(self.fc7(h))))  # ã“ã“ä»¥é™ã¯æ–°ã—ãè¿½åŠ ã—ãŸå±¤ã§ã™ã€‚
        return self.fc8(h)

n_classes = len(dnames)
model = Illust2Vec(n_classes)
model = L.Classifier(model)
model.to_gpu(0)
```




    <chainer.links.model.classifier.Classifier at 0x7f3d8c636390>



`__call__`ã®éƒ¨åˆ†ã«`h.unchain_backward()`ã¨ã„ã†è¨˜è¿°ãŒç™»å ´ã—ã¾ã—ãŸã€‚`unchain_backward`ã¯ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚ã‚‹ä¸­é–“å‡ºåŠ›`Variable` ãªã©ã‹ã‚‰å‘¼ã°ã‚Œã€ãã®æ™‚ç‚¹ã‚ˆã‚Šå‰ã®ã‚ã‚‰ã‚†ã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒãƒ¼ãƒ‰ã®æ¥ç¶šã‚’æ–­ã¡åˆ‡ã‚Šã¾ã™ã€‚ãã®ãŸã‚ã€å­¦ç¿’æ™‚ã«ã¯ã“ã‚ŒãŒå‘¼ã°ã‚ŒãŸæ™‚ç‚¹ã‚ˆã‚Šå‰ã®å±¤ã«èª¤å·®ãŒä¼ã‚ã‚‰ãªããªã‚Šã€çµæœã¨ã—ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ›´æ–°ã‚‚è¡Œã‚ã‚Œãªããªã‚Šã¾ã™ã€‚

å‰è¿°ã®

> å­¦ç¿’æ™‚ã«ã¯ã€Illust2Vecç”±æ¥ã®éƒ¨åˆ†ï¼ˆ3å±¤ç›®ä»¥ä¸‹ã®éƒ¨åˆ†ï¼‰ã®é‡ã¿ã¯å›ºå®šã—ã¦ãŠãã¾ã™

ã“ã‚Œã‚’è¡Œã†ãŸã‚ã®ã‚³ãƒ¼ãƒ‰ãŒã€ã“ã®`h.unchain_backward()`ã§ã™ã€‚

ã“ã®ã‚ãŸã‚Šã®ä»•çµ„ã¿ã«ã¤ã„ã¦ã€ã•ã‚‰ã«è©³ã—ãã¯ã€Define-by-Runã«ã‚ˆã‚‹Chainerã®autogradã®ä»•çµ„ã¿ã‚’èª¬æ˜ã—ã¦ã„ã‚‹ã“ã¡ã‚‰ã®è¨˜äº‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚: [1-file Chainerã‚’ä½œã‚‹](http://qiita.com/mitmul/items/37d3932292cdd560d418)

## 5. å­¦ç¿’

ãã‚Œã§ã¯ã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã€å­¦ç¿’ã‚’è¡Œã£ã¦ã¿ã¾ã™ã€‚ã¾ãšå¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ãŠãã¾ã™ã€‚


```python
from chainer import iterators
from chainer import training
from chainer import optimizers
from chainer.training import extensions
from chainer.training import triggers
from chainer.dataset import concat_examples
```

æ¬¡ã«å­¦ç¿’ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã—ã¾ã™ã€‚ä»Šå›ã¯

- ãƒãƒƒãƒã‚µã‚¤ã‚º64
- å­¦ç¿’ç‡ã¯0.01ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã€10ã‚¨ãƒãƒƒã‚¯ç›®ã§0.1å€ã«ã™ã‚‹
- 20ã‚¨ãƒãƒƒã‚¯ã§å­¦ç¿’çµ‚äº†

ã¨ã—ã¾ã™ã€‚


```python
batchsize = 64
gpu_id = 0
initial_lr = 0.01
lr_drop_epoch = [10]
lr_drop_ratio = 0.1
train_epoch = 20
```


```python
train_iter = iterators.MultiprocessIterator(train, batchsize)
valid_iter = iterators.MultiprocessIterator(
    valid, batchsize, repeat=False, shuffle=False)

optimizer = optimizers.MomentumSGD(lr=initial_lr)
optimizer.setup(model)
optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001))

updater = training.StandardUpdater(
    train_iter, optimizer, device=gpu_id)

trainer = training.Trainer(updater, (train_epoch, 'epoch'), out='AnimeFace-result')
trainer.extend(extensions.LogReport())
trainer.extend(extensions.observe_lr())

# æ¨™æº–å‡ºåŠ›ã«æ›¸ãå‡ºã—ãŸã„å€¤
trainer.extend(extensions.PrintReport(
    ['epoch',
     'main/loss',
     'main/accuracy',
     'validation/main/loss',
     'validation/main/accuracy',
     'elapsed_time',
     'lr']))

# ãƒ­ã‚¹ã®ãƒ—ãƒ­ãƒƒãƒˆã‚’æ¯ã‚¨ãƒãƒƒã‚¯è‡ªå‹•çš„ã«ä¿å­˜
trainer.extend(extensions.PlotReport(
        ['main/loss',
         'validation/main/loss'],
        'epoch', file_name='loss.png'))

# ç²¾åº¦ã®ãƒ—ãƒ­ãƒƒãƒˆã‚‚æ¯ã‚¨ãƒãƒƒã‚¯è‡ªå‹•çš„ã«ä¿å­˜
trainer.extend(extensions.PlotReport(
        ['main/accuracy',
         'validation/main/accuracy'],
        'epoch', file_name='accuracy.png'))

# ãƒ¢ãƒ‡ãƒ«ã®trainãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’Falseã«è¨­å®šã—ã¦validationã™ã‚‹extension
trainer.extend(extensions.Evaluator(valid_iter, model, device=gpu_id))

# æŒ‡å®šã—ãŸã‚¨ãƒãƒƒã‚¯ã”ã¨ã«å­¦ç¿’ç‡ã‚’10åˆ†ã®1ã«ã™ã‚‹

def lr_drop(trainer):
    trainer.updater.get_optimizer('main').lr *= lr_drop_ratio

trainer.extend(
    lr_drop,
    trigger=triggers.ManualScheduleTrigger(lr_drop_epoch, 'epoch'))

trainer.run()
```

    epoch       main/loss   main/accuracy  validation/main/loss  validation/main/accuracy  elapsed_time  lr        
    [J1           1.57341     0.626759       0.596217              0.834188                  24.9535       0.01        
    [J2           0.592884    0.834851       0.529221              0.854108                  41.7383       0.01        
    [J3           0.398748    0.881312       0.487583              0.867564                  58.4842       0.01        
    [J4           0.33203     0.90418        0.427361              0.884571                  75.3357       0.01        
    [J5           0.227967    0.932119       0.433671              0.887747                  91.9539       0.01        
    [J6           0.207433    0.937707       0.426151              0.889243                  108.593       0.01        
    [J7           0.170046    0.948986       0.410441              0.890739                  125.667       0.01        
    [J8           0.142838    0.956436       0.406034              0.899671                  142.823       0.01        
    [J9           0.142185    0.958092       0.416965              0.894737                  159.578       0.01        
    [J10          0.117041    0.965956       0.408871              0.899111                  176.432       0.01        
    [J11          0.0944959   0.972889       0.388597              0.896906                  193.15        0.001       
    [J12          0.0734699   0.980753       0.355984              0.907484                  209.978       0.001       
    [J13          0.0731715   0.979719       0.376939              0.901167                  227.502       0.001       
    [J14          0.0722281   0.983651       0.364557              0.910362                  244.675       0.001       
    [J15          0.069801    0.982099       0.366278              0.90513                   261.601       0.001       
    [J16          0.0736745   0.97875        0.362352              0.904981                  278.607       0.001       
    [J17          0.0646118   0.982926       0.351286              0.90457                   295.928       0.001       
    [J18          0.0591635   0.984789       0.360433              0.907484                  312.508       0.001       
    [J19          0.0612314   0.985099       0.35836               0.907597                  330.281       0.001       
    [J20          0.0577607   0.985824       0.357249              0.90786                   347.66        0.001       


6åˆ†åŠãã‚‰ã„ã§å­¦ç¿’ãŒçµ‚ã‚ã‚Šã¾ã—ãŸã€‚æ¨™æº–å‡ºåŠ›ã«å‡ºã‚‹é€”ä¸­çµŒéã¯ä¸Šè¨˜ã®ã‚ˆã†ãªæ„Ÿã˜ã§ã—ãŸã€‚æœ€çµ‚çš„ã«æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã‚‚90%ä»¥ä¸Šã®accuracyãŒå‡ºã›ã¦ã„ã¾ã™ã­ã€‚ã§ã¯ã€ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹å­¦ç¿’çµŒéã§ã®ãƒ­ã‚¹ã‚«ãƒ¼ãƒ–ã¨accuracyã®ã‚«ãƒ¼ãƒ–ã‚’è¡¨ç¤ºã—ã¦ã¿ã¾ã™ã€‚


```python
from IPython.display import Image
Image(filename='AnimeFace-result/loss.png')
```




![png](5-Write-new-dataset-class_ja_files/5-Write-new-dataset-class_ja_34_0.png)




```python
Image(filename='AnimeFace-result/accuracy.png')
```




![png](5-Write-new-dataset-class_ja_files/5-Write-new-dataset-class_ja_35_0.png)



ç„¡äº‹åæŸã—ã¦ã„ã‚‹æ„Ÿã˜ãŒã—ã¾ã™ã€‚

æœ€å¾Œã«ã€ã„ãã¤ã‹validationãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ç”»åƒã‚’å–ã‚Šå‡ºã—ã¦ãã¦å€‹åˆ¥ã®åˆ†é¡çµæœã‚’è¦‹ã¦ã¿ã¾ã™ã€‚


```python
%matplotlib inline
import matplotlib.pyplot as plt

from PIL import Image
from chainer import cuda
```


```python
chainer.config.train = False
for _ in range(10):
    x, t = valid[np.random.randint(len(valid))]
    x = cuda.to_gpu(x)
    y = F.softmax(model.predictor(x[None, ...]))
    
    pred = os.path.basename(dnames[int(y.data.argmax())])
    label = os.path.basename(dnames[t])
    
    print('pred:', pred, 'label:', label, pred == label)

    x = cuda.to_cpu(x)
    x += mean[:, None, None]
    x = x / 256
    x = np.clip(x, 0, 1)
    plt.imshow(x.transpose(1, 2, 0))
    plt.show()
```

    pred: 010_izumi_konata label: 010_izumi_konata True



![png](5-Write-new-dataset-class_ja_files/5-Write-new-dataset-class_ja_38_1.png)


    pred: 134_nunnally_lamperouge label: 134_nunnally_lamperouge True



![png](5-Write-new-dataset-class_ja_files/5-Write-new-dataset-class_ja_38_3.png)


    pred: 120_asakura_yume label: 120_asakura_yume True



![png](5-Write-new-dataset-class_ja_files/5-Write-new-dataset-class_ja_38_5.png)


    pred: 081_yuzuhara_konomi label: 081_yuzuhara_konomi True



![png](5-Write-new-dataset-class_ja_files/5-Write-new-dataset-class_ja_38_7.png)


    pred: 185_akihime_sumomo label: 185_akihime_sumomo True



![png](5-Write-new-dataset-class_ja_files/5-Write-new-dataset-class_ja_38_9.png)


    pred: 001_kinomoto_sakura label: 001_kinomoto_sakura True



![png](5-Write-new-dataset-class_ja_files/5-Write-new-dataset-class_ja_38_11.png)


    pred: 159_andou_mahoro label: 159_andou_mahoro True



![png](5-Write-new-dataset-class_ja_files/5-Write-new-dataset-class_ja_38_13.png)


    pred: 105_yuno label: 105_yuno True



![png](5-Write-new-dataset-class_ja_files/5-Write-new-dataset-class_ja_38_15.png)


    pred: 097_kamikita_komari label: 097_kamikita_komari True



![png](5-Write-new-dataset-class_ja_files/5-Write-new-dataset-class_ja_38_17.png)


    pred: 051_houjou_reika label: 051_houjou_reika True



![png](5-Write-new-dataset-class_ja_files/5-Write-new-dataset-class_ja_38_19.png)


ãƒ©ãƒ³ãƒ€ãƒ ã«10æšé¸ã‚“ã§ã¿ãŸã¨ã“ã‚ã“ã®ç”»åƒãŸã¡ã«å¯¾ã—ã¦ã¯å…¨ã¦æ­£è§£ã§ãã¾ã—ãŸã€‚

æœ€å¾Œã«ã€ã„ã¤ã‹ä½•ã‹ã«ä½¿ã†ã‹ã‚‚ã—ã‚Œãªã„ã®ã§ã€ä¸€å¿œsnapshotã‚’ä¿å­˜ã—ã¦ãŠãã¾ã™ã€‚


```python
from chainer import serializers

serializers.save_npz('animeface.model', model)
```

## 6. ãŠã¾ã‘1ï¼šãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹ã‚’ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒã§æ›¸ãæ–¹æ³•

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹ã‚’ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒã§æ›¸ãã«ã¯ã€`chainer.dataset.DatasetMixin`ã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã—ãŸè‡ªå‰ã‚¯ãƒ©ã‚¹ã‚’ç”¨æ„ã™ã‚Œã°è‰¯ã„ã§ã™ã€‚ãã®ã‚¯ãƒ©ã‚¹ã¯`__len__`ãƒ¡ã‚½ãƒƒãƒ‰ã¨`get_example`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã¤å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚


```python
class MyDataset(chainer.dataset.DatasetMixin):
    
    def __init__(self, image_paths, labels):
        self.image_paths = image_paths
        self.labels = labels
        
    def __len__(self):
        return len(self.image_paths)
    
    def get_example(self, i):
        img = cv.imread(self.image_paths[i])
        img = img.transpose(2, 0, 1).astype(np.float32)
        label = self.labels[i]
        return img, label
```

ã“ã‚Œã¯ã€ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã¨ã€ãã‚Œã«å¯¾å¿œã—ãŸé †ç•ªã§ãƒ©ãƒ™ãƒ«ã‚’ä¸¦ã¹ãŸãƒªã‚¹ãƒˆã‚’æ¸¡ã—ã¦ãŠãã€`[]`ã‚¢ã‚¯ã‚»ã‚µã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æŒ‡å®šã™ã‚‹ã¨ã€å¯¾å¿œã™ã‚‹ãƒ‘ã‚¹ã‹ã‚‰ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§ã€ãƒ©ãƒ™ãƒ«ã¨ä¸¦ã¹ãŸã‚¿ãƒ—ãƒ«ã‚’è¿”ã™ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹ã«ãªã£ã¦ã„ã¾ã™ã€‚ä¾‹ãˆã°ã€ä»¥ä¸‹ã®ã‚ˆã†ã«ä½¿ãˆã¾ã™ã€‚

```python
image_files = ['images/hoge_0_1.png', 'images/hoge_5_1.png', 'images/hoge_2_1.png', 'images/hoge_3_1.png', ...]
labels = [0, 5, 2, 3, ...]

dataset = MyDataset(image_files, labels)

img, label = dataset[2]

#=> èª­ã¿è¾¼ã¾ã‚ŒãŸ 'images/hoge_2_1.png' ç”»åƒãƒ‡ãƒ¼ã‚¿ã¨ã€ãã®ãƒ©ãƒ™ãƒ«ï¼ˆã“ã“ã§ã¯2ï¼‰ãŒè¿”ã‚‹
```

ã“ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ãã®ã¾ã¾Iteratorã«æ¸¡ã™ã“ã¨ãŒã§ãã€Trainerã‚’ä½¿ã£ãŸå­¦ç¿’ã«ä½¿ãˆã¾ã™ã€‚ã¤ã¾ã‚Šã€

```python
train_iter = iterators.MultiprocessIterator(dataset, batchsize=128)
```

ã®ã‚ˆã†ã«ã—ã¦ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‚’ä½œã£ã¦ã€Updaterã«Optimizerã¨ä¸€ç·’ã«æ¸¡ã›ã°ã€Trainerã‚’ã„ã¤ã‚‚é€šã‚Šã«ä½¿ãˆã¾ã™ã€‚

## 7. ãŠã¾ã‘2ï¼šæœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½œã‚Šæ–¹

å®Ÿã¯Chainerã®Trainerã¨ä¸€ç·’ã«ä½¿ã†ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€**å˜ãªã‚‹Pythonã®ãƒªã‚¹ãƒˆã§OK**ã§ã™ã€‚ã©ã†ã„ã†ã“ã¨ã‹ã¨ã„ã†ã¨ã€`len()`ã§é•·ã•ãŒå–å¾—ã§ãã€`[]`ã‚¢ã‚¯ã‚»ã‚µã§è¦ç´ ãŒå–ã‚Šå‡ºã›ã‚‹ã‚‚ã®ãªã‚‰ã€**å…¨ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æ‰±ã†äº‹ãŒã§ãã‚‹**ã¨ã„ã†ã“ã¨ã§ã™ã€‚ä¾‹ãˆã°ã€

```python
data_list = [(x1, t1), (x2, t2), ...]
```

ã®ã‚ˆã†ãª`(ãƒ‡ãƒ¼ã‚¿, ãƒ©ãƒ™ãƒ«)`ã¨ã„ã†ã‚¿ãƒ—ãƒ«ã®ãƒªã‚¹ãƒˆã‚’ä½œã‚Œã°ã€ã“ã‚Œã¯Iteratorã«æ¸¡ã™ã“ã¨ãŒã§ãã¾ã™ã€‚

```python
train_iter = iterators.MultiprocessIterator(data_list, batchsize=128)
```

ãŸã ã“ã†ã„ã£ãŸã‚„ã‚Šã‹ãŸã®æ¬ ç‚¹ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’å­¦ç¿’å‰ã«ãƒ¡ãƒ¢ãƒªã«è¼‰ã›ãªã‘ã‚Œã°ã„ã‘ãªã„ç‚¹ã§ã™ã€‚ã“ã‚Œã‚’é˜²ããŸã‚ã«ã€ImageDatasetã¨TupleDatasetã‚’çµ„ã¿åˆã‚ã›ã‚‹æ–¹æ³•ã‚„LabaledImageDatasetã¨ã„ã£ãŸã‚¯ãƒ©ã‚¹ãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚è©³ã—ãã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã”å‚ç…§ãã ã•ã„ã€‚
http://docs.chainer.org/en/stable/reference/datasets.html#general-datasets
